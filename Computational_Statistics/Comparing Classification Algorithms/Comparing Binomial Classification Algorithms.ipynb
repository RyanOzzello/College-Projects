{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binomial Classification\n",
    "## Logistic Regression From Scratch\n",
    "This blog uses logistic regression on breast cancer data to predict if a patient has cancer based on 9 different features. I have added to this blog's code a from scratch train_test_spilt function, training and prediction functions, as well as the k-fold cross validation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2020-09-18 19:52:06--  https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19889 (19K) [application/x-httpd-php]\n",
      "Saving to: 'dataset.csv'\n",
      "\n",
      "     0K .......... .........                                  100%  326K=0.06s\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000025,5,1,1,1,2,1,3,1,1,2\n",
      "1002945,5,4,4,5,7,10,3,2,1,2\n",
      "1015425,3,1,1,1,2,2,3,1,1,2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-18 19:52:06 (326 KB/s) - 'dataset.csv' saved [19889/19889]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "# Pass wget command off to shell to download the data and name it \n",
    "!wget -O dataset.csv https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\n",
    "!head -3 dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id number</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id number  Clump Thickness  Uniformity of Cell Size  \\\n",
       "0    1000025                5                        1   \n",
       "1    1002945                5                        4   \n",
       "2    1015425                3                        1   \n",
       "3    1016277                6                        8   \n",
       "4    1017023                4                        1   \n",
       "\n",
       "   Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
       "0                         1                  1                            2   \n",
       "1                         4                  5                            7   \n",
       "2                         1                  1                            2   \n",
       "3                         8                  1                            3   \n",
       "4                         1                  3                            2   \n",
       "\n",
       "  Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "0           1                3                1        1      2  \n",
       "1          10                3                2        1      2  \n",
       "2           2                3                1        1      2  \n",
       "3           4                3                7        1      2  \n",
       "4           1                3                1        1      2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('dataset.csv', names=[\n",
    "  \"id number\",\n",
    "  \"Clump Thickness\",\n",
    "  \"Uniformity of Cell Size\",\n",
    "  \"Uniformity of Cell Shape\",\n",
    "  \"Marginal Adhesion\",\n",
    "  \"Single Epithelial Cell Size\",\n",
    "  \"Bare Nuclei\",\n",
    "  \"Bland Chromatin\",\n",
    "  \"Normal Nucleoli\",\n",
    "  \"Mitoses\",\n",
    "  \"Class\"\n",
    "])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id number                       0\n",
       "Clump Thickness                 0\n",
       "Uniformity of Cell Size         0\n",
       "Uniformity of Cell Shape        0\n",
       "Marginal Adhesion               0\n",
       "Single Epithelial Cell Size     0\n",
       "Bare Nuclei                    16\n",
       "Bland Chromatin                 0\n",
       "Normal Nucleoli                 0\n",
       "Mitoses                         0\n",
       "Class                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.replace('?',np.NaN)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select features\n",
    "X = df[[\"Clump Thickness\",\n",
    "  \"Uniformity of Cell Size\",\n",
    "  \"Uniformity of Cell Shape\",\n",
    "  \"Marginal Adhesion\",\n",
    "  \"Single Epithelial Cell Size\",\n",
    "  \"Bare Nuclei\",\n",
    "  \"Bland Chromatin\",\n",
    "  \"Normal Nucleoli\",\n",
    "  \"Mitoses\"\n",
    "]].values.astype(np.float32)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.where(np.isnan(X))\n",
    "X[idx] = np.take(np.nanmedian(X, axis = 0), idx[1])\n",
    "\n",
    "y = df['Class'].values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Y\n",
    "We change the labels that were originally (2 for negative , 4 for positive) --> (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((699,), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if y[0] == 2:\n",
    "  y = np.array(y == 4, dtype=np.float32)\n",
    "y.shape, y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias Factor\n",
    "To make this a proper linear model after $y=mx + b$ with $b$ as the bias factor. We just add a column of 1's to the front of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  5.,  1.,  1.,  1.,  2.,  1.,  3.,  1.,  1.],\n",
       "       [ 1.,  5.,  4.,  4.,  5.,  7., 10.,  3.,  2.,  1.],\n",
       "       [ 1.,  3.,  1.,  1.,  1.,  2.,  2.,  3.,  1.,  1.],\n",
       "       [ 1.,  6.,  8.,  8.,  1.,  3.,  4.,  3.,  7.,  1.],\n",
       "       [ 1.,  4.,  1.,  1.,  3.,  2.,  1.,  3.,  1.,  1.],\n",
       "       [ 1.,  8., 10., 10.,  8.,  7., 10.,  9.,  7.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  2., 10.,  3.,  1.,  1.],\n",
       "       [ 1.,  2.,  1.,  2.,  1.,  2.,  1.,  3.,  1.,  1.],\n",
       "       [ 1.,  2.,  1.,  1.,  1.,  2.,  1.,  1.,  1.,  5.],\n",
       "       [ 1.,  4.,  2.,  1.,  1.,  2.,  1.,  2.,  1.,  1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.hstack((np.ones((len(X), 1)), X))\n",
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 699, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, n = X.shape\n",
    "K = 2 # 2 classes\n",
    "K, m, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "Following from maximum likelihood estimation, we are using the idea of negative log likelihood to design an objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights\n",
    "theta = np.zeros(n)\n",
    "\n",
    "# Sigmoid (Logistic)\n",
    "def g(z):\n",
    "  \"\"\" sigmoid \"\"\"\n",
    "  return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Model\n",
    "def h(X, theta):\n",
    "  return g(X @ theta)\n",
    "\n",
    "# Objective or cost function\n",
    "def J(preds, y):\n",
    "  return 1/m * (-y @ np.log(preds) - (1 - y) @ np.log(1 - preds))\n",
    "\n",
    "# Gradient\n",
    "def compute_gradient(theta, X, y):\n",
    "  preds = h(X, theta)\n",
    "  gradient = 1/m * X.T @ (preds - y)\n",
    "  return gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data Up\n",
    "To test LR properly on new data, I implemented a train_test_split function from scratch (versus using sklearn function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (x,y) shape: (559, 10) (559,) \n",
      "Test (x,y) shape: (139, 10) (139,)\n"
     ]
    }
   ],
   "source": [
    "def my_train_test_split(X, y, train_perc):\n",
    "    train_end_ind = int(X.shape[0] * train_perc)  \n",
    "    train_x = X[0:train_end_ind]\n",
    "    train_y = y[0:train_end_ind]\n",
    "    test_x = X[train_end_ind:-1]\n",
    "    test_y = y[train_end_ind:-1]\n",
    "\n",
    "    return (train_x, train_y, test_x, test_y)\n",
    "\n",
    "\n",
    "train_x, train_y, test_x, test_y = my_train_test_split(X, y, 0.8)\n",
    "print(\"Train (x,y) shape:\", train_x.shape, train_y.shape, \"\\nTest (x,y) shape:\", test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop\n",
    "I implement train and test functions to use in my cross validation function later and for ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (loss, acc): (0.11071898232627445, 0.9588550983899821)\n",
      "Testing (loss, acc): (0.015275531393884854, 1.0)\n"
     ]
    }
   ],
   "source": [
    "def train_LR_from_scratch(X, y, iters, alpha):\n",
    "    theta = np.zeros(10)\n",
    "    \n",
    "    hist = {'loss': [], 'acc': []} # Performance history\n",
    "    \n",
    "    for i in range(iters):\n",
    "        \n",
    "        gradient = compute_gradient(theta, X, y)\n",
    "        theta -= alpha * gradient # Update weights based on gradient of cost function\n",
    "\n",
    "        # loss\n",
    "        preds = h(X, theta)\n",
    "        loss = J(preds, y) \n",
    "        hist['loss'].append(loss) # Measure and store predicted loss\n",
    "\n",
    "        # acc\n",
    "        c = 0\n",
    "        for j in range(len(y)):\n",
    "            if (h(X[j], theta) > .5) == y[j]:\n",
    "              c += 1\n",
    "        acc = c / len(y)\n",
    "        hist['acc'].append(acc) # Compute and store accuracy\n",
    "\n",
    "    return (loss,acc, theta, hist)\n",
    "\n",
    "def test_LR_from_scratch(X, y, theta):\n",
    "    # loss\n",
    "    preds = h(X, theta)\n",
    "    loss = J(preds, y) \n",
    " \n",
    "    # acc\n",
    "    c = 0\n",
    "    for j in range(len(y)):\n",
    "        if (h(X[j], theta) > .5) == y[j]:\n",
    "          c += 1\n",
    "    acc = c / len(y)\n",
    "\n",
    "    return (loss,acc)\n",
    "\n",
    "iters = 1000\n",
    "alpha = 0.1\n",
    "\n",
    "train_loss_from_scratch, train_acc_from_scratch, theta, hist = train_LR_from_scratch(train_x, train_y, iters, alpha)\n",
    "test_loss_from_scratch, test_acc_from_scratch = test_LR_from_scratch(test_x, test_y, theta)\n",
    "\n",
    "print(f'Training (loss, acc): {(train_loss_from_scratch,train_acc_from_scratch)}')\n",
    "print(f'Testing (loss, acc): {(test_loss_from_scratch, test_acc_from_scratch)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Mean Accuracy: 0.964 (0.018)\n"
     ]
    }
   ],
   "source": [
    "# No fancy features we're used in the sklearn version so that we are comparing apples to apples\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Init model\n",
    "LR = LogisticRegression(random_state=0)\n",
    "# 10-fold cv using sklearn\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1, random_state=1)\n",
    "scores = cross_val_score(LR, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "kfold_sklearn_acc = mean(scores)\n",
    "# Performance\n",
    "print('LogisticRegression Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation Comparisons\n",
    "We are unable to compare the from scratch and sklearn logistic regression algorithms using the packaged pair t-test with 5x2 cross validation since it takes two sklearn models as parameters for comparison. So, we have settled to just comparing the 10-fold cross validation of each.\n",
    "\n",
    "For the sake of learning, I have included how to use the pair t-test with 5x2 cross validation by comparing LR and LDA to show how to do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_Fold Cross Validation\n",
    "def cv_split(X, y, start_ind_test, end_ind_test, end_cap):\n",
    "    # k-1 train segments\n",
    "    train_x = np.append(X[0:start_ind_test], X[end_ind_test:end_cap], axis=0)\n",
    "    train_y = np.append(y[0:start_ind_test], y[end_ind_test:end_cap], axis=0)\n",
    "    # 1 test segment\n",
    "    test_x = X[start_ind_test:end_ind_test]\n",
    "    test_y = y[start_ind_test:end_ind_test]\n",
    "\n",
    "    \n",
    "    return (train_x, train_y, test_x, test_y)\n",
    "\n",
    "def kfold_cv_from_scratch(train_func, test_func, X, y, iters, alpha, folds):\n",
    "    hist = {'loss': [], 'acc': []} # Performance history\n",
    "    fold_size = (X.shape[0]) // folds\n",
    "    for i in range(folds):\n",
    "        start_ind_test = i * fold_size\n",
    "        end_ind_test = min(len(X) - 1, start_ind_test + fold_size)\n",
    "        end_cap = fold_size * folds\n",
    "\n",
    "        train_x, train_y, test_x, test_y = cv_split(X, y, start_ind_test, end_ind_test, end_cap)\n",
    "        \n",
    "        _, _, theta, _  = train_func(train_x, train_y, iters, alpha)\n",
    "        loss, acc = test_func(test_x, test_y, theta)\n",
    "        \n",
    "        hist['loss'].append(loss)\n",
    "        hist['acc'].append(acc)\n",
    "    \n",
    "    avg_loss, avg_acc = mean(hist['loss']), mean(hist['acc'])\n",
    "    \n",
    "    return (avg_loss, avg_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binomial Classification: Logistic Regession From Scratch vs sklearn\n",
    "We can see that both models perform extremely similarly in terms of accuracy with LR sklean beating the from scratch model by half of a percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folds = 10\n",
    "_, kfold_from_scratch_acc = kfold_cv_from_scratch(train_LR_from_scratch, test_LR_from_scratch, X, y, iters, alpha, folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (From Scratch, SKLearn): (0.9594202898550724, 0.9642443064182193), Difference: -0.0048240165631469045\n"
     ]
    }
   ],
   "source": [
    "dif = kfold_from_scratch_acc - kfold_sklearn_acc\n",
    "print(f'Mean Accuracy (From Scratch, SKLearn): {kfold_from_scratch_acc, kfold_sklearn_acc}, Difference: {dif}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paired T-Test 5x2 Cross Validation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.074, t-Statistic: 2.257\n",
      "Algorithms probably have the same performance\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.evaluate import paired_ttest_5x2cv\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "\n",
    "t,p = paired_ttest_5x2cv(estimator1=LR, estimator2=LDA, X=X, y=y, scoring='accuracy', random_seed=1)\n",
    "# summarize\n",
    "print('P-value: %.3f, t-Statistic: %.3f' % (p, t))\n",
    "# interpret the result\n",
    "if p <= 0.05:\n",
    "    print('Difference between mean performance is probably real')\n",
    "else:\n",
    "    print('Algorithms probably have the same performance')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
